{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from scipy import io\n",
    "import numpy as np\n",
    "from keras.utils import np_utils\n",
    "from sklearn.model_selection import train_test_split\n",
    "from PIL import Image\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation, Flatten\n",
    "from keras.layers import Conv2D, MaxPool2D, Dropout\n",
    "from keras.callbacks import Callback, TensorBoard\n",
    "\n",
    "from deepsense import neptune\n",
    "\n",
    "\n",
    "def array_2d_to_image(array, autorescale=True):\n",
    "    assert array.min() >= 0\n",
    "    assert len(array.shape) == 2\n",
    "    if array.max() <= 1 and autorescale:\n",
    "        array = 255 * array\n",
    "    array = array.astype('uint8')\n",
    "    return Image.fromarray(array)\n",
    "\n",
    "\n",
    "class NeptuneCallback(Callback):\n",
    "    def __init__(self, images_per_epoch=-1):\n",
    "        self.epoch_id = 0\n",
    "        self.images_per_epoch = images_per_epoch\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs={}):\n",
    "        self.epoch_id += 1\n",
    "\n",
    "        # logging numeric channels\n",
    "        ctx.channel_send('Log-loss training', self.epoch_id, logs['loss'])\n",
    "        ctx.channel_send('Log-loss validation', self.epoch_id, logs['val_loss'])\n",
    "        ctx.channel_send('Accuracy training', self.epoch_id, logs['acc'])\n",
    "        ctx.channel_send('Accuracy validation', self.epoch_id, logs['val_acc'])\n",
    "\n",
    "        # Predict the digits for images of the test set.\n",
    "        validation_predictions = model.predict_classes(X_test)\n",
    "        scores = model.predict(X_test)\n",
    "\n",
    "        # Identify the incorrectly classified images and send them to Neptune Dashboard.\n",
    "        image_per_epoch = 0\n",
    "        for index, (prediction, actual) in enumerate(zip(validation_predictions, Y_test.argmax(axis=1))):\n",
    "            if prediction != actual:\n",
    "                if image_per_epoch == self.images_per_epoch:\n",
    "                    break\n",
    "                image_per_epoch += 1\n",
    "\n",
    "                ctx.channel_send('false_predictions', neptune.Image(\n",
    "                    name='[{}] pred: {} true: {}'.format(self.epoch_id, letters[prediction], letters[actual]),\n",
    "                    description=\"\\n\".join([\n",
    "                        \"{} {:5.1f}% {}\".format(letters[i], 100 * score, \"!!!\" if i == actual else \"\")\n",
    "                        for i, score in enumerate(scores[index])]),\n",
    "                    data=array_2d_to_image(X_test[index,:,:,0])))\n",
    "\n",
    "\n",
    "data = io.loadmat(\"/input/notMNIST_small.mat\")\n",
    "X = data['images']\n",
    "y = data['labels']\n",
    "\n",
    "resolution = 28  # 28x28 images, grayscale\n",
    "classes = 10     # 10 letters: ABCDEFGHIJ\n",
    "\n",
    "# transforming data for TensorFlow backend\n",
    "X = np.transpose(X, (2, 0, 1))\n",
    "X = X.reshape((-1, resolution, resolution, 1))\n",
    "X = X.astype('float32') / 255.\n",
    "\n",
    "# 3 -> [0., 0., 0., 1., 0., 0., 0., 0., 0., 0.]\n",
    "y = y.astype('int32')\n",
    "Y = np_utils.to_categorical(y, classes)\n",
    "\n",
    "# splitting data into training and test sets\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(\n",
    "    X, Y,\n",
    "    test_size=0.20,\n",
    "    random_state=137)\n",
    "\n",
    "letters = \"ABCDEFGHIJ\"\n",
    "\n",
    "ctx = neptune.Context()\n",
    "\n",
    "# create neural network architecture\n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "model.add(Conv2D(16, (3, 3), activation='relu',\n",
    "                 input_shape=(resolution, resolution, 1)))\n",
    "# model.add(Conv2D(16, (3, 3), activation='relu'))  # uncomment!\n",
    "model.add(MaxPool2D())\n",
    "\n",
    "# model.add(Conv2D(32, (3, 3), activation='relu'))  # uncomment!\n",
    "# model.add(Conv2D(32, (3, 3), activation='relu'))  # uncomment!\n",
    "model.add(MaxPool2D())\n",
    "\n",
    "model.add(Flatten())\n",
    "# model.add(Dropout(0.5))  # uncomment!\n",
    "model.add(Dense(classes, activation='softmax'))\n",
    "\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.fit(X_train, Y_train,\n",
    "          epochs=10,\n",
    "          batch_size=32,\n",
    "          validation_data=(X_test, Y_test),\n",
    "          verbose=2,\n",
    "          callbacks=[NeptuneCallback(images_per_epoch=20)])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Neptune",
   "language": "",
   "name": "neptune-kernel"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
